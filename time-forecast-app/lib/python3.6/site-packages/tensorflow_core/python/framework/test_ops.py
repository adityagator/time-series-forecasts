"""Python wrappers around TensorFlow ops.

This file is MACHINE GENERATED! Do not edit.
Original C++ source file: test_ops.cc
"""

import collections

from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
from tensorflow.python.eager import context as _context
from tensorflow.python.eager import core as _core
from tensorflow.python.eager import execute as _execute
from tensorflow.python.framework import dtypes as _dtypes

from tensorflow.python.framework import op_def_registry as _op_def_registry
from tensorflow.python.framework import ops as _ops
from tensorflow.python.framework import op_def_library as _op_def_library
from tensorflow.python.util.deprecation import deprecated_endpoints
from tensorflow.python.util import dispatch as _dispatch
from tensorflow.python.util.tf_export import tf_export


@_dispatch.add_dispatch_list
@tf_export('a')
def a(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "A", name, tld.op_callbacks)
      return _result
    except _core._FallbackException:
      try:
        return a_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "A", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "A", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

A = tf_export("raw_ops.A")(_ops.to_raw_op(a))


def a_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"A", 1, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "A", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr')
def attr(a, name=None):
  r"""TODO: add doc.

  Args:
    a: An `int`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "Attr", name, tld.op_callbacks,
        "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  a = _execute.make_int(a, "a")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "Attr", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
Attr = tf_export("raw_ops.Attr")(_ops.to_raw_op(attr))


def attr_eager_fallback(a, name, ctx):
  a = _execute.make_int(a, "a")
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"Attr", 0, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_bool')
def attr_bool(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `bool`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrBool", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_bool_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_bool, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  a = _execute.make_bool(a, "a")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrBool", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_bool, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrBool = tf_export("raw_ops.AttrBool")(_ops.to_raw_op(attr_bool))


def attr_bool_eager_fallback(a, name, ctx):
  a = _execute.make_bool(a, "a")
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrBool", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_bool_list')
def attr_bool_list(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of `bools`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrBoolList", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_bool_list_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_bool_list, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_bool_list' Op, not %r." % a)
  a = [_execute.make_bool(_b, "a") for _b in a]
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrBoolList", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_bool_list, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrBoolList = tf_export("raw_ops.AttrBoolList")(_ops.to_raw_op(attr_bool_list))


def attr_bool_list_eager_fallback(a, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_bool_list' Op, not %r." % a)
  a = [_execute.make_bool(_b, "a") for _b in a]
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrBoolList", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_default')
def attr_default(a="banana", name=None):
  r"""TODO: add doc.

  Args:
    a: An optional `string`. Defaults to `"banana"`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrDefault", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_default_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_default, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if a is None:
    a = "banana"
  a = _execute.make_str(a, "a")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrDefault", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_default, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrDefault = tf_export("raw_ops.AttrDefault")(_ops.to_raw_op(attr_default))


def attr_default_eager_fallback(a, name, ctx):
  if a is None:
    a = "banana"
  a = _execute.make_str(a, "a")
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrDefault", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_empty_list_default')
def attr_empty_list_default(a=[], name=None):
  r"""TODO: add doc.

  Args:
    a: An optional list of `floats`. Defaults to `[]`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrEmptyListDefault", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_empty_list_default_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_empty_list_default, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if a is None:
    a = []
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_empty_list_default' Op, not %r." % a)
  a = [_execute.make_float(_f, "a") for _f in a]
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrEmptyListDefault", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_empty_list_default, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrEmptyListDefault = tf_export("raw_ops.AttrEmptyListDefault")(_ops.to_raw_op(attr_empty_list_default))


def attr_empty_list_default_eager_fallback(a, name, ctx):
  if a is None:
    a = []
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_empty_list_default' Op, not %r." % a)
  a = [_execute.make_float(_f, "a") for _f in a]
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrEmptyListDefault", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_enum')
def attr_enum(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `string` from: `"apples", "oranges"`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrEnum", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_enum_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_enum, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  a = _execute.make_str(a, "a")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrEnum", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_enum, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrEnum = tf_export("raw_ops.AttrEnum")(_ops.to_raw_op(attr_enum))


def attr_enum_eager_fallback(a, name, ctx):
  a = _execute.make_str(a, "a")
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrEnum", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_enum_list')
def attr_enum_list(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of `strings` from: `"apples", "oranges"`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrEnumList", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_enum_list_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_enum_list, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_enum_list' Op, not %r." % a)
  a = [_execute.make_str(_s, "a") for _s in a]
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrEnumList", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_enum_list, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrEnumList = tf_export("raw_ops.AttrEnumList")(_ops.to_raw_op(attr_enum_list))


def attr_enum_list_eager_fallback(a, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_enum_list' Op, not %r." % a)
  a = [_execute.make_str(_s, "a") for _s in a]
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrEnumList", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_float')
def attr_float(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `float`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrFloat", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_float_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_float, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  a = _execute.make_float(a, "a")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrFloat", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_float, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrFloat = tf_export("raw_ops.AttrFloat")(_ops.to_raw_op(attr_float))


def attr_float_eager_fallback(a, name, ctx):
  a = _execute.make_float(a, "a")
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrFloat", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_list_default')
def attr_list_default(a=[5, 15], name=None):
  r"""TODO: add doc.

  Args:
    a: An optional list of `ints`. Defaults to `[5, 15]`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrListDefault", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_list_default_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_list_default, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if a is None:
    a = [5, 15]
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_list_default' Op, not %r." % a)
  a = [_execute.make_int(_i, "a") for _i in a]
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrListDefault", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_list_default, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrListDefault = tf_export("raw_ops.AttrListDefault")(_ops.to_raw_op(attr_list_default))


def attr_list_default_eager_fallback(a, name, ctx):
  if a is None:
    a = [5, 15]
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_list_default' Op, not %r." % a)
  a = [_execute.make_int(_i, "a") for _i in a]
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrListDefault", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_list_min')
def attr_list_min(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of `ints` that has length `>= 2`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrListMin", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_list_min_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_list_min, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_list_min' Op, not %r." % a)
  a = [_execute.make_int(_i, "a") for _i in a]
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrListMin", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_list_min, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrListMin = tf_export("raw_ops.AttrListMin")(_ops.to_raw_op(attr_list_min))


def attr_list_min_eager_fallback(a, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_list_min' Op, not %r." % a)
  a = [_execute.make_int(_i, "a") for _i in a]
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrListMin", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_list_type_default')
def attr_list_type_default(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of at least 1 `Tensor` objects with the same type.
    b: A list with the same length as `a` of `Tensor` objects with the same type as `a`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrListTypeDefault", name,
        tld.op_callbacks, a, b)
      return _result
    except _core._FallbackException:
      try:
        return attr_list_type_default_eager_fallback(
            a, b, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_list_type_default, a=a, b=b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_list_type_default' Op, not %r." % a)
  _attr_N = len(a)
  if not isinstance(b, (list, tuple)):
    raise TypeError(
        "Expected list for 'b' argument to "
        "'attr_list_type_default' Op, not %r." % b)
  if len(b) != _attr_N:
    raise ValueError(
        "List argument 'b' to 'attr_list_type_default' Op with length %d "
        "must match length %d of argument 'a'." %
        (len(b), _attr_N))
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrListTypeDefault", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_list_type_default, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrListTypeDefault = tf_export("raw_ops.AttrListTypeDefault")(_ops.to_raw_op(attr_list_type_default))


def attr_list_type_default_eager_fallback(a, b, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_list_type_default' Op, not %r." % a)
  _attr_N = len(a)
  if not isinstance(b, (list, tuple)):
    raise TypeError(
        "Expected list for 'b' argument to "
        "'attr_list_type_default' Op, not %r." % b)
  if len(b) != _attr_N:
    raise ValueError(
        "List argument 'b' to 'attr_list_type_default' Op with length %d "
        "must match length %d of argument 'a'." %
        (len(b), _attr_N))
  _attr_T, _inputs_T = _execute.args_to_matching_eager(list(a) + list(b), ctx, _dtypes.int32)
  _inputs_T = [_inputs_T[:_attr_N]] + _inputs_T[_attr_N:]
  _inputs_T = _inputs_T[:1] + [_inputs_T[1:]]
  (a, b) = _inputs_T
  _inputs_flat = list(a) + list(b)
  _attrs = ("T", _attr_T, "N", _attr_N)
  _result = _execute.execute(b"AttrListTypeDefault", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_min')
def attr_min(a, name=None):
  r"""TODO: add doc.

  Args:
    a: An `int` that is `>= 5`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrMin", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_min_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_min, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  a = _execute.make_int(a, "a")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrMin", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_min, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrMin = tf_export("raw_ops.AttrMin")(_ops.to_raw_op(attr_min))


def attr_min_eager_fallback(a, name, ctx):
  a = _execute.make_int(a, "a")
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrMin", 0, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_partial_shape')
def attr_partial_shape(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `tf.TensorShape` or list of `ints`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrPartialShape", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_partial_shape_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_partial_shape, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  a = _execute.make_shape(a, "a")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrPartialShape", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_partial_shape, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrPartialShape = tf_export("raw_ops.AttrPartialShape")(_ops.to_raw_op(attr_partial_shape))


def attr_partial_shape_eager_fallback(a, name, ctx):
  a = _execute.make_shape(a, "a")
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrPartialShape", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_partial_shape_list')
def attr_partial_shape_list(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of shapes (each a `tf.TensorShape` or list of `ints`).
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrPartialShapeList", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_partial_shape_list_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_partial_shape_list, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_partial_shape_list' Op, not %r." % a)
  a = [_execute.make_shape(_s, "a") for _s in a]
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrPartialShapeList", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_partial_shape_list, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrPartialShapeList = tf_export("raw_ops.AttrPartialShapeList")(_ops.to_raw_op(attr_partial_shape_list))


def attr_partial_shape_list_eager_fallback(a, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_partial_shape_list' Op, not %r." % a)
  a = [_execute.make_shape(_s, "a") for _s in a]
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrPartialShapeList", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_shape')
def attr_shape(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `tf.TensorShape` or list of `ints`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrShape", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_shape_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_shape, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  a = _execute.make_shape(a, "a")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrShape", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_shape, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrShape = tf_export("raw_ops.AttrShape")(_ops.to_raw_op(attr_shape))


def attr_shape_eager_fallback(a, name, ctx):
  a = _execute.make_shape(a, "a")
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrShape", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_shape_list')
def attr_shape_list(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of shapes (each a `tf.TensorShape` or list of `ints`).
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrShapeList", name,
        tld.op_callbacks, "a", a)
      return _result
    except _core._FallbackException:
      try:
        return attr_shape_list_eager_fallback(
            a=a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_shape_list, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_shape_list' Op, not %r." % a)
  a = [_execute.make_shape(_s, "a") for _s in a]
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrShapeList", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_shape_list, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrShapeList = tf_export("raw_ops.AttrShapeList")(_ops.to_raw_op(attr_shape_list))


def attr_shape_list_eager_fallback(a, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'attr_shape_list' Op, not %r." % a)
  a = [_execute.make_shape(_s, "a") for _s in a]
  _inputs_flat = []
  _attrs = ("a", a)
  _result = _execute.execute(b"AttrShapeList", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('attr_type_default')
def attr_type_default(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "AttrTypeDefault", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return attr_type_default_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              attr_type_default, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "AttrTypeDefault", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          attr_type_default, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
AttrTypeDefault = tf_export("raw_ops.AttrTypeDefault")(_ops.to_raw_op(attr_type_default))


def attr_type_default_eager_fallback(a, name, ctx):
  _attr_T, (a,) = _execute.args_to_matching_eager([a], ctx, _dtypes.int32)
  _inputs_flat = [a]
  _attrs = ("T", _attr_T)
  _result = _execute.execute(b"AttrTypeDefault", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('b')
def b(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "B", name, tld.op_callbacks)
      return _result
    except _core._FallbackException:
      try:
        return b_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "B", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "B", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

B = tf_export("raw_ops.B")(_ops.to_raw_op(b))


def b_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"B", 1, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "B", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('binary')
def binary(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor`.
    b: A `Tensor`. Must have the same type as `a`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `a`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "Binary", name,
        tld.op_callbacks, a, b)
      return _result
    except _core._FallbackException:
      try:
        return binary_eager_fallback(
            a, b, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              binary, a=a, b=b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "Binary", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          binary, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op._get_attr_type("T"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "Binary", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

Binary = tf_export("raw_ops.Binary")(_ops.to_raw_op(binary))


def binary_eager_fallback(a, b, name, ctx):
  _attr_T, _inputs_T = _execute.args_to_matching_eager([a, b], ctx)
  (a, b) = _inputs_T
  _inputs_flat = [a, b]
  _attrs = ("T", _attr_T)
  _result = _execute.execute(b"Binary", 1, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "Binary", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

_ComplexStructOutput = collections.namedtuple(
    "ComplexStruct",
    ["a", "b", "c"])


@_dispatch.add_dispatch_list
@tf_export('complex_struct')
def complex_struct(n_a, n_b, t_c, name=None):
  r"""TODO: add doc.

  Args:
    n_a: An `int` that is `>= 0`.
    n_b: An `int` that is `>= 0`.
    t_c: A list of `tf.DTypes`.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (a, b, c).

    a: A list of `n_a` `Tensor` objects with type `int32`.
    b: A list of `n_b` `Tensor` objects with type `int64`.
    c: A list of `Tensor` objects of type `t_c`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "ComplexStruct", name,
        tld.op_callbacks, "n_a", n_a, "n_b", n_b, "t_c", t_c)
      _result = _ComplexStructOutput._make(_result)
      return _result
    except _core._FallbackException:
      try:
        return complex_struct_eager_fallback(
            n_a=n_a, n_b=n_b, t_c=t_c, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              complex_struct, n_a=n_a, n_b=n_b, t_c=t_c, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  n_a = _execute.make_int(n_a, "n_a")
  n_b = _execute.make_int(n_b, "n_b")
  if not isinstance(t_c, (list, tuple)):
    raise TypeError(
        "Expected list for 't_c' argument to "
        "'complex_struct' Op, not %r." % t_c)
  t_c = [_execute.make_type(_t, "t_c") for _t in t_c]
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "ComplexStruct", n_a=n_a, n_b=n_b, t_c=t_c, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          complex_struct, n_a=n_a, n_b=n_b, t_c=t_c, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("n_a", _op._get_attr_int("n_a"), "n_b",
              _op._get_attr_int("n_b"), "t_c", _op.get_attr("t_c"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "ComplexStruct", _inputs_flat, _attrs, _result)
  _result = [_result[:n_a]] + _result[n_a:]
  _result = _result[:1] + [_result[1:1 + n_b]] + _result[1 + n_b:]
  _result = _result[:2] + [_result[2:]]
  _result = _ComplexStructOutput._make(_result)
  return _result

ComplexStruct = tf_export("raw_ops.ComplexStruct")(_ops.to_raw_op(complex_struct))


def complex_struct_eager_fallback(n_a, n_b, t_c, name, ctx):
  n_a = _execute.make_int(n_a, "n_a")
  n_b = _execute.make_int(n_b, "n_b")
  if not isinstance(t_c, (list, tuple)):
    raise TypeError(
        "Expected list for 't_c' argument to "
        "'complex_struct' Op, not %r." % t_c)
  t_c = [_execute.make_type(_t, "t_c") for _t in t_c]
  _inputs_flat = []
  _attrs = ("n_a", n_a, "n_b", n_b, "t_c", t_c)
  _result = _execute.execute(b"ComplexStruct", n_a + n_b + len(t_c),
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "ComplexStruct", _inputs_flat, _attrs, _result)
  _result = [_result[:n_a]] + _result[n_a:]
  _result = _result[:1] + [_result[1:1 + n_b]] + _result[1 + n_b:]
  _result = _result[:2] + [_result[2:]]
  _result = _ComplexStructOutput._make(_result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('copy_op')
def copy_op(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `a`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "CopyOp", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return copy_op_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              copy_op, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "CopyOp", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          copy_op, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op._get_attr_type("T"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "CopyOp", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

CopyOp = tf_export("raw_ops.CopyOp")(_ops.to_raw_op(copy_op))


def copy_op_eager_fallback(a, name, ctx):
  _attr_T, (a,) = _execute.args_to_matching_eager([a], ctx)
  _inputs_flat = [a]
  _attrs = ("T", _attr_T)
  _result = _execute.execute(b"CopyOp", 1, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "CopyOp", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('default_attrs')
def default_attrs(string_val="abc", string_list_val=["abc", ""], int_val=123, int_list_val=[1, 2, 3], float_val=10, float_list_val=[10], bool_val=True, bool_list_val=[True, False], type_val=_dtypes.int32, type_list_val=[_dtypes.int32, _dtypes.float32], shape_val=[2, 1], shape_list_val=[[], [1]], tensor_val=_execute.make_tensor("""dtype: DT_INT32 tensor_shape { } int_val: 1""", "tensor_val"), tensor_list_val=[_execute.make_tensor(_pb, "tensor_list_val") for _pb in ("""dtype: DT_INT32 tensor_shape { } int_val: 1""",)], name=None):
  r"""TODO: add doc.

  Args:
    string_val: An optional `string`. Defaults to `"abc"`.
    string_list_val: An optional list of `strings`. Defaults to `["abc", ""]`.
    int_val: An optional `int`. Defaults to `123`.
    int_list_val: An optional list of `ints`. Defaults to `[1, 2, 3]`.
    float_val: An optional `float`. Defaults to `10`.
    float_list_val: An optional list of `floats`. Defaults to `[10]`.
    bool_val: An optional `bool`. Defaults to `True`.
    bool_list_val: An optional list of `bools`. Defaults to `[True, False]`.
    type_val: An optional `tf.DType`. Defaults to `tf.int32`.
    type_list_val: An optional list of `tf.DTypes`. Defaults to `[tf.int32, tf.float32]`.
    shape_val: An optional `tf.TensorShape` or list of `ints`. Defaults to `[2, 1]`.
    shape_list_val: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[[], [1]]`.
    tensor_val: An optional `tf.TensorProto`. Defaults to `dtype: DT_INT32 tensor_shape { } int_val: 1`.
    tensor_list_val: An optional list of `tf.TensorProto` objects. Defaults to `[dtype: DT_INT32 tensor_shape { } int_val: 1]`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "DefaultAttrs", name,
        tld.op_callbacks, "string_val", string_val, "string_list_val",
        string_list_val, "int_val", int_val, "int_list_val", int_list_val,
        "float_val", float_val, "float_list_val", float_list_val, "bool_val",
        bool_val, "bool_list_val", bool_list_val, "type_val", type_val,
        "type_list_val", type_list_val, "shape_val", shape_val,
        "shape_list_val", shape_list_val, "tensor_val", tensor_val,
        "tensor_list_val", tensor_list_val)
      return _result
    except _core._FallbackException:
      try:
        return default_attrs_eager_fallback(
            string_val=string_val, string_list_val=string_list_val,
            int_val=int_val, int_list_val=int_list_val, float_val=float_val,
            float_list_val=float_list_val, bool_val=bool_val,
            bool_list_val=bool_list_val, type_val=type_val,
            type_list_val=type_list_val, shape_val=shape_val,
            shape_list_val=shape_list_val, tensor_val=tensor_val,
            tensor_list_val=tensor_list_val, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              default_attrs, string_val=string_val,
                             string_list_val=string_list_val, int_val=int_val,
                             int_list_val=int_list_val, float_val=float_val,
                             float_list_val=float_list_val, bool_val=bool_val,
                             bool_list_val=bool_list_val, type_val=type_val,
                             type_list_val=type_list_val, shape_val=shape_val,
                             shape_list_val=shape_list_val,
                             tensor_val=tensor_val,
                             tensor_list_val=tensor_list_val, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if string_val is None:
    string_val = "abc"
  string_val = _execute.make_str(string_val, "string_val")
  if string_list_val is None:
    string_list_val = ["abc", ""]
  if not isinstance(string_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'string_list_val' argument to "
        "'default_attrs' Op, not %r." % string_list_val)
  string_list_val = [_execute.make_str(_s, "string_list_val") for _s in string_list_val]
  if int_val is None:
    int_val = 123
  int_val = _execute.make_int(int_val, "int_val")
  if int_list_val is None:
    int_list_val = [1, 2, 3]
  if not isinstance(int_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'int_list_val' argument to "
        "'default_attrs' Op, not %r." % int_list_val)
  int_list_val = [_execute.make_int(_i, "int_list_val") for _i in int_list_val]
  if float_val is None:
    float_val = 10
  float_val = _execute.make_float(float_val, "float_val")
  if float_list_val is None:
    float_list_val = [10]
  if not isinstance(float_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'float_list_val' argument to "
        "'default_attrs' Op, not %r." % float_list_val)
  float_list_val = [_execute.make_float(_f, "float_list_val") for _f in float_list_val]
  if bool_val is None:
    bool_val = True
  bool_val = _execute.make_bool(bool_val, "bool_val")
  if bool_list_val is None:
    bool_list_val = [True, False]
  if not isinstance(bool_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'bool_list_val' argument to "
        "'default_attrs' Op, not %r." % bool_list_val)
  bool_list_val = [_execute.make_bool(_b, "bool_list_val") for _b in bool_list_val]
  if type_val is None:
    type_val = _dtypes.int32
  type_val = _execute.make_type(type_val, "type_val")
  if type_list_val is None:
    type_list_val = [_dtypes.int32, _dtypes.float32]
  if not isinstance(type_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'type_list_val' argument to "
        "'default_attrs' Op, not %r." % type_list_val)
  type_list_val = [_execute.make_type(_t, "type_list_val") for _t in type_list_val]
  if shape_val is None:
    shape_val = [2, 1]
  shape_val = _execute.make_shape(shape_val, "shape_val")
  if shape_list_val is None:
    shape_list_val = [[], [1]]
  if not isinstance(shape_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'shape_list_val' argument to "
        "'default_attrs' Op, not %r." % shape_list_val)
  shape_list_val = [_execute.make_shape(_s, "shape_list_val") for _s in shape_list_val]
  if tensor_val is None:
    tensor_val = _execute.make_tensor("""dtype: DT_INT32 tensor_shape { } int_val: 1""", "tensor_val")
  tensor_val = _execute.make_tensor(tensor_val, "tensor_val")
  if tensor_list_val is None:
    tensor_list_val = [_execute.make_tensor(_pb, "tensor_list_val") for _pb in ("""dtype: DT_INT32 tensor_shape { } int_val: 1""",)]
  if not isinstance(tensor_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'tensor_list_val' argument to "
        "'default_attrs' Op, not %r." % tensor_list_val)
  tensor_list_val = [_execute.make_tensor(_t, "tensor_list_val") for _t in tensor_list_val]
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "DefaultAttrs", string_val=string_val,
                        string_list_val=string_list_val, int_val=int_val,
                        int_list_val=int_list_val, float_val=float_val,
                        float_list_val=float_list_val, bool_val=bool_val,
                        bool_list_val=bool_list_val, type_val=type_val,
                        type_list_val=type_list_val, shape_val=shape_val,
                        shape_list_val=shape_list_val, tensor_val=tensor_val,
                        tensor_list_val=tensor_list_val, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          default_attrs, string_val=string_val,
                         string_list_val=string_list_val, int_val=int_val,
                         int_list_val=int_list_val, float_val=float_val,
                         float_list_val=float_list_val, bool_val=bool_val,
                         bool_list_val=bool_list_val, type_val=type_val,
                         type_list_val=type_list_val, shape_val=shape_val,
                         shape_list_val=shape_list_val, tensor_val=tensor_val,
                         tensor_list_val=tensor_list_val, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
DefaultAttrs = tf_export("raw_ops.DefaultAttrs")(_ops.to_raw_op(default_attrs))


def default_attrs_eager_fallback(string_val, string_list_val, int_val, int_list_val, float_val, float_list_val, bool_val, bool_list_val, type_val, type_list_val, shape_val, shape_list_val, tensor_val, tensor_list_val, name, ctx):
  if string_val is None:
    string_val = "abc"
  string_val = _execute.make_str(string_val, "string_val")
  if string_list_val is None:
    string_list_val = ["abc", ""]
  if not isinstance(string_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'string_list_val' argument to "
        "'default_attrs' Op, not %r." % string_list_val)
  string_list_val = [_execute.make_str(_s, "string_list_val") for _s in string_list_val]
  if int_val is None:
    int_val = 123
  int_val = _execute.make_int(int_val, "int_val")
  if int_list_val is None:
    int_list_val = [1, 2, 3]
  if not isinstance(int_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'int_list_val' argument to "
        "'default_attrs' Op, not %r." % int_list_val)
  int_list_val = [_execute.make_int(_i, "int_list_val") for _i in int_list_val]
  if float_val is None:
    float_val = 10
  float_val = _execute.make_float(float_val, "float_val")
  if float_list_val is None:
    float_list_val = [10]
  if not isinstance(float_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'float_list_val' argument to "
        "'default_attrs' Op, not %r." % float_list_val)
  float_list_val = [_execute.make_float(_f, "float_list_val") for _f in float_list_val]
  if bool_val is None:
    bool_val = True
  bool_val = _execute.make_bool(bool_val, "bool_val")
  if bool_list_val is None:
    bool_list_val = [True, False]
  if not isinstance(bool_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'bool_list_val' argument to "
        "'default_attrs' Op, not %r." % bool_list_val)
  bool_list_val = [_execute.make_bool(_b, "bool_list_val") for _b in bool_list_val]
  if type_val is None:
    type_val = _dtypes.int32
  type_val = _execute.make_type(type_val, "type_val")
  if type_list_val is None:
    type_list_val = [_dtypes.int32, _dtypes.float32]
  if not isinstance(type_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'type_list_val' argument to "
        "'default_attrs' Op, not %r." % type_list_val)
  type_list_val = [_execute.make_type(_t, "type_list_val") for _t in type_list_val]
  if shape_val is None:
    shape_val = [2, 1]
  shape_val = _execute.make_shape(shape_val, "shape_val")
  if shape_list_val is None:
    shape_list_val = [[], [1]]
  if not isinstance(shape_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'shape_list_val' argument to "
        "'default_attrs' Op, not %r." % shape_list_val)
  shape_list_val = [_execute.make_shape(_s, "shape_list_val") for _s in shape_list_val]
  if tensor_val is None:
    tensor_val = _execute.make_tensor("""dtype: DT_INT32 tensor_shape { } int_val: 1""", "tensor_val")
  tensor_val = _execute.make_tensor(tensor_val, "tensor_val")
  if tensor_list_val is None:
    tensor_list_val = [_execute.make_tensor(_pb, "tensor_list_val") for _pb in ("""dtype: DT_INT32 tensor_shape { } int_val: 1""",)]
  if not isinstance(tensor_list_val, (list, tuple)):
    raise TypeError(
        "Expected list for 'tensor_list_val' argument to "
        "'default_attrs' Op, not %r." % tensor_list_val)
  tensor_list_val = [_execute.make_tensor(_t, "tensor_list_val") for _t in tensor_list_val]
  _inputs_flat = []
  _attrs = ("string_val", string_val, "string_list_val", string_list_val,
  "int_val", int_val, "int_list_val", int_list_val, "float_val", float_val,
  "float_list_val", float_list_val, "bool_val", bool_val, "bool_list_val",
  bool_list_val, "type_val", type_val, "type_list_val", type_list_val,
  "shape_val", shape_val, "shape_list_val", shape_list_val, "tensor_val",
  tensor_val, "tensor_list_val", tensor_list_val)
  _result = _execute.execute(b"DefaultAttrs", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('device_placement_op')
def device_placement_op(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `string`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "DevicePlacementOp", name,
        tld.op_callbacks)
      return _result
    except _core._FallbackException:
      try:
        return device_placement_op_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              device_placement_op, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "DevicePlacementOp", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          device_placement_op, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "DevicePlacementOp", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

DevicePlacementOp = tf_export("raw_ops.DevicePlacementOp")(_ops.to_raw_op(device_placement_op))


def device_placement_op_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"DevicePlacementOp", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "DevicePlacementOp", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

_FiveFloatOutputsOutput = collections.namedtuple(
    "FiveFloatOutputs",
    ["a", "b", "c", "d", "e"])


@_dispatch.add_dispatch_list
@tf_export('five_float_outputs')
def five_float_outputs(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (a, b, c, d, e).

    a: A `Tensor` of type `float32`.
    b: A `Tensor` of type `float32`.
    c: A `Tensor` of type `float32`.
    d: A `Tensor` of type `float32`.
    e: A `Tensor` of type `float32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "FiveFloatOutputs", name,
        tld.op_callbacks)
      _result = _FiveFloatOutputsOutput._make(_result)
      return _result
    except _core._FallbackException:
      try:
        return five_float_outputs_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              five_float_outputs, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "FiveFloatOutputs", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          five_float_outputs, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "FiveFloatOutputs", _inputs_flat, _attrs, _result)
  _result = _FiveFloatOutputsOutput._make(_result)
  return _result

FiveFloatOutputs = tf_export("raw_ops.FiveFloatOutputs")(_ops.to_raw_op(five_float_outputs))


def five_float_outputs_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"FiveFloatOutputs", 5, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "FiveFloatOutputs", _inputs_flat, _attrs, _result)
  _result = _FiveFloatOutputsOutput._make(_result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('float_input')
def float_input(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "FloatInput", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return float_input_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              float_input, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "FloatInput", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          float_input, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
FloatInput = tf_export("raw_ops.FloatInput")(_ops.to_raw_op(float_input))


def float_input_eager_fallback(a, name, ctx):
  a = _ops.convert_to_tensor(a, _dtypes.float32)
  _inputs_flat = [a]
  _attrs = None
  _result = _execute.execute(b"FloatInput", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('float_output')
def float_output(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "FloatOutput", name,
        tld.op_callbacks)
      return _result
    except _core._FallbackException:
      try:
        return float_output_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              float_output, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "FloatOutput", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          float_output, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "FloatOutput", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

FloatOutput = tf_export("raw_ops.FloatOutput")(_ops.to_raw_op(float_output))


def float_output_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"FloatOutput", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "FloatOutput", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

_FloatOutputStringOutputOutput = collections.namedtuple(
    "FloatOutputStringOutput",
    ["a", "b"])


@_dispatch.add_dispatch_list
@tf_export('float_output_string_output')
def float_output_string_output(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (a, b).

    a: A `Tensor` of type `float32`.
    b: A `Tensor` of type `string`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "FloatOutputStringOutput",
        name, tld.op_callbacks)
      _result = _FloatOutputStringOutputOutput._make(_result)
      return _result
    except _core._FallbackException:
      try:
        return float_output_string_output_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              float_output_string_output, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "FloatOutputStringOutput", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          float_output_string_output, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "FloatOutputStringOutput", _inputs_flat, _attrs, _result)
  _result = _FloatOutputStringOutputOutput._make(_result)
  return _result

FloatOutputStringOutput = tf_export("raw_ops.FloatOutputStringOutput")(_ops.to_raw_op(float_output_string_output))


def float_output_string_output_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"FloatOutputStringOutput", 2,
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "FloatOutputStringOutput", _inputs_flat, _attrs, _result)
  _result = _FloatOutputStringOutputOutput._make(_result)
  return _result

_Foo1Output = collections.namedtuple(
    "Foo1",
    ["d", "e"])


@_dispatch.add_dispatch_list
@tf_export('foo1')
def foo1(a, b, c, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type `float32`.
    b: A `Tensor` of type `int32`.
    c: A `Tensor` of type `int32`.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (d, e).

    d: A `Tensor` of type `float32`.
    e: A `Tensor` of type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "Foo1", name, tld.op_callbacks,
        a, b, c)
      _result = _Foo1Output._make(_result)
      return _result
    except _core._FallbackException:
      try:
        return foo1_eager_fallback(
            a, b, c, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              foo1, a=a, b=b, c=c, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "Foo1", a=a, b=b, c=c, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          foo1, a=a, b=b, c=c, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "Foo1", _inputs_flat, _attrs, _result)
  _result = _Foo1Output._make(_result)
  return _result

Foo1 = tf_export("raw_ops.Foo1")(_ops.to_raw_op(foo1))


def foo1_eager_fallback(a, b, c, name, ctx):
  a = _ops.convert_to_tensor(a, _dtypes.float32)
  b = _ops.convert_to_tensor(b, _dtypes.int32)
  c = _ops.convert_to_tensor(c, _dtypes.int32)
  _inputs_flat = [a, b, c]
  _attrs = None
  _result = _execute.execute(b"Foo1", 2, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "Foo1", _inputs_flat, _attrs, _result)
  _result = _Foo1Output._make(_result)
  return _result

_Foo2Output = collections.namedtuple(
    "Foo2",
    ["d", "e"])


@_dispatch.add_dispatch_list
@tf_export('foo2')
def foo2(a, b, c, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type `float32`.
    b: A `Tensor` of type `string`.
    c: A `Tensor` of type `string`.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (d, e).

    d: A `Tensor` of type `float32`.
    e: A `Tensor` of type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "Foo2", name, tld.op_callbacks,
        a, b, c)
      _result = _Foo2Output._make(_result)
      return _result
    except _core._FallbackException:
      try:
        return foo2_eager_fallback(
            a, b, c, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              foo2, a=a, b=b, c=c, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "Foo2", a=a, b=b, c=c, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          foo2, a=a, b=b, c=c, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "Foo2", _inputs_flat, _attrs, _result)
  _result = _Foo2Output._make(_result)
  return _result

Foo2 = tf_export("raw_ops.Foo2")(_ops.to_raw_op(foo2))


def foo2_eager_fallback(a, b, c, name, ctx):
  a = _ops.convert_to_tensor(a, _dtypes.float32)
  b = _ops.convert_to_tensor(b, _dtypes.string)
  c = _ops.convert_to_tensor(c, _dtypes.string)
  _inputs_flat = [a, b, c]
  _attrs = None
  _result = _execute.execute(b"Foo2", 2, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "Foo2", _inputs_flat, _attrs, _result)
  _result = _Foo2Output._make(_result)
  return _result

_Foo3Output = collections.namedtuple(
    "Foo3",
    ["d", "e"])


@_dispatch.add_dispatch_list
@tf_export('foo3')
def foo3(a, b, c, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type `float32`.
    b: A `Tensor` of type `string`.
    c: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (d, e).

    d: A `Tensor` of type `float32`.
    e: A `Tensor` of type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "Foo3", name, tld.op_callbacks,
        a, b, c)
      _result = _Foo3Output._make(_result)
      return _result
    except _core._FallbackException:
      try:
        return foo3_eager_fallback(
            a, b, c, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              foo3, a=a, b=b, c=c, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "Foo3", a=a, b=b, c=c, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          foo3, a=a, b=b, c=c, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "Foo3", _inputs_flat, _attrs, _result)
  _result = _Foo3Output._make(_result)
  return _result

Foo3 = tf_export("raw_ops.Foo3")(_ops.to_raw_op(foo3))


def foo3_eager_fallback(a, b, c, name, ctx):
  a = _ops.convert_to_tensor(a, _dtypes.float32)
  b = _ops.convert_to_tensor(b, _dtypes.string)
  c = _ops.convert_to_tensor(c, _dtypes.float32)
  _inputs_flat = [a, b, c]
  _attrs = None
  _result = _execute.execute(b"Foo3", 2, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "Foo3", _inputs_flat, _attrs, _result)
  _result = _Foo3Output._make(_result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('func_attr')
def func_attr(f, name=None):
  r"""TODO: add doc.

  Args:
    f: A function decorated with @Defun.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "FuncAttr", name,
        tld.op_callbacks, "f", f)
      return _result
    except _core._FallbackException:
      try:
        return func_attr_eager_fallback(
            f=f, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              func_attr, f=f, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "FuncAttr", f=f, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          func_attr, f=f, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
FuncAttr = tf_export("raw_ops.FuncAttr")(_ops.to_raw_op(func_attr))


def func_attr_eager_fallback(f, name, ctx):
  _inputs_flat = []
  _attrs = ("f", f)
  _result = _execute.execute(b"FuncAttr", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('func_list_attr')
def func_list_attr(f, name=None):
  r"""TODO: add doc.

  Args:
    f: A list of functions decorated with @Defun.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "FuncListAttr", name,
        tld.op_callbacks, "f", f)
      return _result
    except _core._FallbackException:
      try:
        return func_list_attr_eager_fallback(
            f=f, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              func_list_attr, f=f, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(f, (list, tuple)):
    raise TypeError(
        "Expected list for 'f' argument to "
        "'func_list_attr' Op, not %r." % f)
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "FuncListAttr", f=f, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          func_list_attr, f=f, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
FuncListAttr = tf_export("raw_ops.FuncListAttr")(_ops.to_raw_op(func_list_attr))


def func_list_attr_eager_fallback(f, name, ctx):
  if not isinstance(f, (list, tuple)):
    raise TypeError(
        "Expected list for 'f' argument to "
        "'func_list_attr' Op, not %r." % f)
  _inputs_flat = []
  _attrs = ("f", f)
  _result = _execute.execute(b"FuncListAttr", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('graph_def_version')
def graph_def_version(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "GraphDefVersion", name,
        tld.op_callbacks)
      return _result
    except _core._FallbackException:
      try:
        return graph_def_version_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              graph_def_version, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "GraphDefVersion", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          graph_def_version, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "GraphDefVersion", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

GraphDefVersion = tf_export("raw_ops.GraphDefVersion")(_ops.to_raw_op(graph_def_version))


def graph_def_version_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"GraphDefVersion", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "GraphDefVersion", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('in_polymorphic_twice')
def in_polymorphic_twice(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of `Tensor` objects with the same type.
    b: A list of `Tensor` objects with the same type as `a`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "InPolymorphicTwice", name,
        tld.op_callbacks, a, b)
      return _result
    except _core._FallbackException:
      try:
        return in_polymorphic_twice_eager_fallback(
            a, b, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              in_polymorphic_twice, a=a, b=b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'in_polymorphic_twice' Op, not %r." % a)
  _attr_N = len(a)
  if not isinstance(b, (list, tuple)):
    raise TypeError(
        "Expected list for 'b' argument to "
        "'in_polymorphic_twice' Op, not %r." % b)
  _attr_M = len(b)
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "InPolymorphicTwice", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          in_polymorphic_twice, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
InPolymorphicTwice = tf_export("raw_ops.InPolymorphicTwice")(_ops.to_raw_op(in_polymorphic_twice))


def in_polymorphic_twice_eager_fallback(a, b, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'in_polymorphic_twice' Op, not %r." % a)
  _attr_N = len(a)
  if not isinstance(b, (list, tuple)):
    raise TypeError(
        "Expected list for 'b' argument to "
        "'in_polymorphic_twice' Op, not %r." % b)
  _attr_M = len(b)
  _attr_T, _inputs_T = _execute.args_to_matching_eager(list(a) + list(b), ctx, _dtypes.int32)
  _inputs_T = [_inputs_T[:_attr_N]] + _inputs_T[_attr_N:]
  _inputs_T = _inputs_T[:1] + [_inputs_T[1:]]
  (a, b) = _inputs_T
  _inputs_flat = list(a) + list(b)
  _attrs = ("T", _attr_T, "N", _attr_N, "M", _attr_M)
  _result = _execute.execute(b"InPolymorphicTwice", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('int64_output')
def int64_output(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int64`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "Int64Output", name,
        tld.op_callbacks)
      return _result
    except _core._FallbackException:
      try:
        return int64_output_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              int64_output, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "Int64Output", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          int64_output, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "Int64Output", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

Int64Output = tf_export("raw_ops.Int64Output")(_ops.to_raw_op(int64_output))


def int64_output_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"Int64Output", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "Int64Output", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('int_attr')
def int_attr(foo=1, name=None):
  r"""TODO: add doc.

  Args:
    foo: An optional `int`. Defaults to `1`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int64`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "IntAttr", name,
        tld.op_callbacks, "foo", foo)
      return _result
    except _core._FallbackException:
      try:
        return int_attr_eager_fallback(
            foo=foo, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              int_attr, foo=foo, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if foo is None:
    foo = 1
  foo = _execute.make_int(foo, "foo")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "IntAttr", foo=foo, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          int_attr, foo=foo, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("foo", _op._get_attr_int("foo"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "IntAttr", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

IntAttr = tf_export("raw_ops.IntAttr")(_ops.to_raw_op(int_attr))


def int_attr_eager_fallback(foo, name, ctx):
  if foo is None:
    foo = 1
  foo = _execute.make_int(foo, "foo")
  _inputs_flat = []
  _attrs = ("foo", foo)
  _result = _execute.execute(b"IntAttr", 1, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "IntAttr", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('int_input')
def int_input(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type `int32`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "IntInput", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return int_input_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              int_input, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "IntInput", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          int_input, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
IntInput = tf_export("raw_ops.IntInput")(_ops.to_raw_op(int_input))


def int_input_eager_fallback(a, name, ctx):
  a = _ops.convert_to_tensor(a, _dtypes.int32)
  _inputs_flat = [a]
  _attrs = None
  _result = _execute.execute(b"IntInput", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('int_input_float_input')
def int_input_float_input(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type `int32`.
    b: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "IntInputFloatInput", name,
        tld.op_callbacks, a, b)
      return _result
    except _core._FallbackException:
      try:
        return int_input_float_input_eager_fallback(
            a, b, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              int_input_float_input, a=a, b=b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "IntInputFloatInput", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          int_input_float_input, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
IntInputFloatInput = tf_export("raw_ops.IntInputFloatInput")(_ops.to_raw_op(int_input_float_input))


def int_input_float_input_eager_fallback(a, b, name, ctx):
  a = _ops.convert_to_tensor(a, _dtypes.int32)
  b = _ops.convert_to_tensor(b, _dtypes.float32)
  _inputs_flat = [a, b]
  _attrs = None
  _result = _execute.execute(b"IntInputFloatInput", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('int_input_int_output')
def int_input_int_output(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type `int32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "IntInputIntOutput", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return int_input_int_output_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              int_input_int_output, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "IntInputIntOutput", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          int_input_int_output, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "IntInputIntOutput", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

IntInputIntOutput = tf_export("raw_ops.IntInputIntOutput")(_ops.to_raw_op(int_input_int_output))


def int_input_int_output_eager_fallback(a, name, ctx):
  a = _ops.convert_to_tensor(a, _dtypes.int32)
  _inputs_flat = [a]
  _attrs = None
  _result = _execute.execute(b"IntInputIntOutput", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "IntInputIntOutput", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('int_output')
def int_output(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "IntOutput", name,
        tld.op_callbacks)
      return _result
    except _core._FallbackException:
      try:
        return int_output_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              int_output, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "IntOutput", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          int_output, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "IntOutput", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

IntOutput = tf_export("raw_ops.IntOutput")(_ops.to_raw_op(int_output))


def int_output_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"IntOutput", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "IntOutput", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

_IntOutputFloatOutputOutput = collections.namedtuple(
    "IntOutputFloatOutput",
    ["a", "b"])


@_dispatch.add_dispatch_list
@tf_export('int_output_float_output')
def int_output_float_output(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (a, b).

    a: A `Tensor` of type `int32`.
    b: A `Tensor` of type `float32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "IntOutputFloatOutput", name,
        tld.op_callbacks)
      _result = _IntOutputFloatOutputOutput._make(_result)
      return _result
    except _core._FallbackException:
      try:
        return int_output_float_output_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              int_output_float_output, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "IntOutputFloatOutput", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          int_output_float_output, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "IntOutputFloatOutput", _inputs_flat, _attrs, _result)
  _result = _IntOutputFloatOutputOutput._make(_result)
  return _result

IntOutputFloatOutput = tf_export("raw_ops.IntOutputFloatOutput")(_ops.to_raw_op(int_output_float_output))


def int_output_float_output_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"IntOutputFloatOutput", 2, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "IntOutputFloatOutput", _inputs_flat, _attrs, _result)
  _result = _IntOutputFloatOutputOutput._make(_result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('kernel_label')
def kernel_label(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `string`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "KernelLabel", name,
        tld.op_callbacks)
      return _result
    except _core._FallbackException:
      try:
        return kernel_label_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              kernel_label, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "KernelLabel", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          kernel_label, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "KernelLabel", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

KernelLabel = tf_export("raw_ops.KernelLabel")(_ops.to_raw_op(kernel_label))


def kernel_label_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"KernelLabel", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "KernelLabel", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('kernel_label_required')
def kernel_label_required(input, name=None):
  r"""TODO: add doc.

  Args:
    input: A `Tensor` of type `int32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `string`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "KernelLabelRequired", name,
        tld.op_callbacks, input)
      return _result
    except _core._FallbackException:
      try:
        return kernel_label_required_eager_fallback(
            input, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              kernel_label_required, input=input, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "KernelLabelRequired", input=input, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          kernel_label_required, input=input, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "KernelLabelRequired", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

KernelLabelRequired = tf_export("raw_ops.KernelLabelRequired")(_ops.to_raw_op(kernel_label_required))


def kernel_label_required_eager_fallback(input, name, ctx):
  input = _ops.convert_to_tensor(input, _dtypes.int32)
  _inputs_flat = [input]
  _attrs = None
  _result = _execute.execute(b"KernelLabelRequired", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "KernelLabelRequired", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('list_input')
def list_input(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of at least 1 `Tensor` objects with the same type.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "ListInput", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return list_input_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              list_input, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'list_input' Op, not %r." % a)
  _attr_N = len(a)
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "ListInput", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          list_input, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
ListInput = tf_export("raw_ops.ListInput")(_ops.to_raw_op(list_input))


def list_input_eager_fallback(a, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'list_input' Op, not %r." % a)
  _attr_N = len(a)
  _attr_T, a = _execute.args_to_matching_eager(list(a), ctx)
  _inputs_flat = list(a)
  _attrs = ("N", _attr_N, "T", _attr_T)
  _result = _execute.execute(b"ListInput", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('list_output')
def list_output(T, name=None):
  r"""TODO: add doc.

  Args:
    T: A list of `tf.DTypes` that has length `>= 1`.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `T`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "ListOutput", name,
        tld.op_callbacks, "T", T)
      return _result
    except _core._FallbackException:
      try:
        return list_output_eager_fallback(
            T=T, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              list_output, T=T, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(T, (list, tuple)):
    raise TypeError(
        "Expected list for 'T' argument to "
        "'list_output' Op, not %r." % T)
  T = [_execute.make_type(_t, "T") for _t in T]
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "ListOutput", T=T, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          list_output, T=T, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op.get_attr("T"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "ListOutput", _inputs_flat, _attrs, _result)
  return _result

ListOutput = tf_export("raw_ops.ListOutput")(_ops.to_raw_op(list_output))


def list_output_eager_fallback(T, name, ctx):
  if not isinstance(T, (list, tuple)):
    raise TypeError(
        "Expected list for 'T' argument to "
        "'list_output' Op, not %r." % T)
  T = [_execute.make_type(_t, "T") for _t in T]
  _inputs_flat = []
  _attrs = ("T", T)
  _result = _execute.execute(b"ListOutput", len(T), inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "ListOutput", _inputs_flat, _attrs, _result)
  return _result

_MixedStructOutput = collections.namedtuple(
    "MixedStruct",
    ["a", "b"])


@_dispatch.add_dispatch_list
@tf_export('mixed_struct')
def mixed_struct(n_a, name=None):
  r"""TODO: add doc.

  Args:
    n_a: An `int` that is `>= 0`.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (a, b).

    a: A list of `n_a` `Tensor` objects with type `int32`.
    b: A `Tensor` of type `float32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "MixedStruct", name,
        tld.op_callbacks, "n_a", n_a)
      _result = _MixedStructOutput._make(_result)
      return _result
    except _core._FallbackException:
      try:
        return mixed_struct_eager_fallback(
            n_a=n_a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              mixed_struct, n_a=n_a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  n_a = _execute.make_int(n_a, "n_a")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "MixedStruct", n_a=n_a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          mixed_struct, n_a=n_a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("n_a", _op._get_attr_int("n_a"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "MixedStruct", _inputs_flat, _attrs, _result)
  _result = [_result[:n_a]] + _result[n_a:]
  _result = _MixedStructOutput._make(_result)
  return _result

MixedStruct = tf_export("raw_ops.MixedStruct")(_ops.to_raw_op(mixed_struct))


def mixed_struct_eager_fallback(n_a, name, ctx):
  n_a = _execute.make_int(n_a, "n_a")
  _inputs_flat = []
  _attrs = ("n_a", n_a)
  _result = _execute.execute(b"MixedStruct", n_a + 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "MixedStruct", _inputs_flat, _attrs, _result)
  _result = [_result[:n_a]] + _result[n_a:]
  _result = _MixedStructOutput._make(_result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('n_in_polymorphic_twice')
def n_in_polymorphic_twice(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of `Tensor` objects with the same type.
    b: A list with the same length as `a` of `Tensor` objects with the same type as `a`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "NInPolymorphicTwice", name,
        tld.op_callbacks, a, b)
      return _result
    except _core._FallbackException:
      try:
        return n_in_polymorphic_twice_eager_fallback(
            a, b, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              n_in_polymorphic_twice, a=a, b=b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'n_in_polymorphic_twice' Op, not %r." % a)
  _attr_N = len(a)
  if not isinstance(b, (list, tuple)):
    raise TypeError(
        "Expected list for 'b' argument to "
        "'n_in_polymorphic_twice' Op, not %r." % b)
  if len(b) != _attr_N:
    raise ValueError(
        "List argument 'b' to 'n_in_polymorphic_twice' Op with length %d "
        "must match length %d of argument 'a'." %
        (len(b), _attr_N))
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "NInPolymorphicTwice", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          n_in_polymorphic_twice, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
NInPolymorphicTwice = tf_export("raw_ops.NInPolymorphicTwice")(_ops.to_raw_op(n_in_polymorphic_twice))


def n_in_polymorphic_twice_eager_fallback(a, b, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'n_in_polymorphic_twice' Op, not %r." % a)
  _attr_N = len(a)
  if not isinstance(b, (list, tuple)):
    raise TypeError(
        "Expected list for 'b' argument to "
        "'n_in_polymorphic_twice' Op, not %r." % b)
  if len(b) != _attr_N:
    raise ValueError(
        "List argument 'b' to 'n_in_polymorphic_twice' Op with length %d "
        "must match length %d of argument 'a'." %
        (len(b), _attr_N))
  _attr_T, _inputs_T = _execute.args_to_matching_eager(list(a) + list(b), ctx)
  _inputs_T = [_inputs_T[:_attr_N]] + _inputs_T[_attr_N:]
  _inputs_T = _inputs_T[:1] + [_inputs_T[1:]]
  (a, b) = _inputs_T
  _inputs_flat = list(a) + list(b)
  _attrs = ("T", _attr_T, "N", _attr_N)
  _result = _execute.execute(b"NInPolymorphicTwice", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('n_in_twice')
def n_in_twice(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of `Tensor` objects with type `int32`.
    b: A list with the same length as `a` of `Tensor` objects with type `string`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "NInTwice", name,
        tld.op_callbacks, a, b)
      return _result
    except _core._FallbackException:
      try:
        return n_in_twice_eager_fallback(
            a, b, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              n_in_twice, a=a, b=b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'n_in_twice' Op, not %r." % a)
  _attr_N = len(a)
  if not isinstance(b, (list, tuple)):
    raise TypeError(
        "Expected list for 'b' argument to "
        "'n_in_twice' Op, not %r." % b)
  if len(b) != _attr_N:
    raise ValueError(
        "List argument 'b' to 'n_in_twice' Op with length %d "
        "must match length %d of argument 'a'." %
        (len(b), _attr_N))
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "NInTwice", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          n_in_twice, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
NInTwice = tf_export("raw_ops.NInTwice")(_ops.to_raw_op(n_in_twice))


def n_in_twice_eager_fallback(a, b, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'n_in_twice' Op, not %r." % a)
  _attr_N = len(a)
  if not isinstance(b, (list, tuple)):
    raise TypeError(
        "Expected list for 'b' argument to "
        "'n_in_twice' Op, not %r." % b)
  if len(b) != _attr_N:
    raise ValueError(
        "List argument 'b' to 'n_in_twice' Op with length %d "
        "must match length %d of argument 'a'." %
        (len(b), _attr_N))
  a = _ops.convert_n_to_tensor(a, _dtypes.int32)
  b = _ops.convert_n_to_tensor(b, _dtypes.string)
  _inputs_flat = list(a) + list(b)
  _attrs = ("N", _attr_N)
  _result = _execute.execute(b"NInTwice", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('n_in_two_type_variables')
def n_in_two_type_variables(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of `Tensor` objects with the same type.
    b: A list with the same length as `a` of `Tensor` objects with the same type.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "NInTwoTypeVariables", name,
        tld.op_callbacks, a, b)
      return _result
    except _core._FallbackException:
      try:
        return n_in_two_type_variables_eager_fallback(
            a, b, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              n_in_two_type_variables, a=a, b=b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'n_in_two_type_variables' Op, not %r." % a)
  _attr_N = len(a)
  if not isinstance(b, (list, tuple)):
    raise TypeError(
        "Expected list for 'b' argument to "
        "'n_in_two_type_variables' Op, not %r." % b)
  if len(b) != _attr_N:
    raise ValueError(
        "List argument 'b' to 'n_in_two_type_variables' Op with length %d "
        "must match length %d of argument 'a'." %
        (len(b), _attr_N))
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "NInTwoTypeVariables", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          n_in_two_type_variables, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
NInTwoTypeVariables = tf_export("raw_ops.NInTwoTypeVariables")(_ops.to_raw_op(n_in_two_type_variables))


def n_in_two_type_variables_eager_fallback(a, b, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'n_in_two_type_variables' Op, not %r." % a)
  _attr_N = len(a)
  if not isinstance(b, (list, tuple)):
    raise TypeError(
        "Expected list for 'b' argument to "
        "'n_in_two_type_variables' Op, not %r." % b)
  if len(b) != _attr_N:
    raise ValueError(
        "List argument 'b' to 'n_in_two_type_variables' Op with length %d "
        "must match length %d of argument 'a'." %
        (len(b), _attr_N))
  _attr_S, a = _execute.args_to_matching_eager(list(a), ctx)
  _attr_T, b = _execute.args_to_matching_eager(list(b), ctx)
  _inputs_flat = list(a) + list(b)
  _attrs = ("S", _attr_S, "T", _attr_T, "N", _attr_N)
  _result = _execute.execute(b"NInTwoTypeVariables", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('n_ints_in')
def n_ints_in(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of at least 2 `Tensor` objects with type `int32`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "NIntsIn", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return n_ints_in_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              n_ints_in, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'n_ints_in' Op, not %r." % a)
  _attr_N = len(a)
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "NIntsIn", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          n_ints_in, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
NIntsIn = tf_export("raw_ops.NIntsIn")(_ops.to_raw_op(n_ints_in))


def n_ints_in_eager_fallback(a, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'n_ints_in' Op, not %r." % a)
  _attr_N = len(a)
  a = _ops.convert_n_to_tensor(a, _dtypes.int32)
  _inputs_flat = list(a)
  _attrs = ("N", _attr_N)
  _result = _execute.execute(b"NIntsIn", 0, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('n_ints_out')
def n_ints_out(N, name=None):
  r"""TODO: add doc.

  Args:
    N: An `int` that is `>= 2`.
    name: A name for the operation (optional).

  Returns:
    A list of `N` `Tensor` objects with type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "NIntsOut", name,
        tld.op_callbacks, "N", N)
      return _result
    except _core._FallbackException:
      try:
        return n_ints_out_eager_fallback(
            N=N, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              n_ints_out, N=N, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  N = _execute.make_int(N, "N")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "NIntsOut", N=N, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          n_ints_out, N=N, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("N", _op._get_attr_int("N"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "NIntsOut", _inputs_flat, _attrs, _result)
  return _result

NIntsOut = tf_export("raw_ops.NIntsOut")(_ops.to_raw_op(n_ints_out))


def n_ints_out_eager_fallback(N, name, ctx):
  N = _execute.make_int(N, "N")
  _inputs_flat = []
  _attrs = ("N", N)
  _result = _execute.execute(b"NIntsOut", N, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "NIntsOut", _inputs_flat, _attrs, _result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('n_ints_out_default')
def n_ints_out_default(N=3, name=None):
  r"""TODO: add doc.

  Args:
    N: An optional `int` that is `>= 2`. Defaults to `3`.
    name: A name for the operation (optional).

  Returns:
    A list of `N` `Tensor` objects with type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "NIntsOutDefault", name,
        tld.op_callbacks, "N", N)
      return _result
    except _core._FallbackException:
      try:
        return n_ints_out_default_eager_fallback(
            N=N, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              n_ints_out_default, N=N, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if N is None:
    N = 3
  N = _execute.make_int(N, "N")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "NIntsOutDefault", N=N, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          n_ints_out_default, N=N, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("N", _op._get_attr_int("N"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "NIntsOutDefault", _inputs_flat, _attrs, _result)
  return _result

NIntsOutDefault = tf_export("raw_ops.NIntsOutDefault")(_ops.to_raw_op(n_ints_out_default))


def n_ints_out_default_eager_fallback(N, name, ctx):
  if N is None:
    N = 3
  N = _execute.make_int(N, "N")
  _inputs_flat = []
  _attrs = ("N", N)
  _result = _execute.execute(b"NIntsOutDefault", N, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "NIntsOutDefault", _inputs_flat, _attrs, _result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('n_polymorphic_in')
def n_polymorphic_in(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of at least 2 `Tensor` objects with the same type.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "NPolymorphicIn", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return n_polymorphic_in_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              n_polymorphic_in, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'n_polymorphic_in' Op, not %r." % a)
  _attr_N = len(a)
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "NPolymorphicIn", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          n_polymorphic_in, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
NPolymorphicIn = tf_export("raw_ops.NPolymorphicIn")(_ops.to_raw_op(n_polymorphic_in))


def n_polymorphic_in_eager_fallback(a, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'n_polymorphic_in' Op, not %r." % a)
  _attr_N = len(a)
  _attr_T, a = _execute.args_to_matching_eager(list(a), ctx)
  _inputs_flat = list(a)
  _attrs = ("T", _attr_T, "N", _attr_N)
  _result = _execute.execute(b"NPolymorphicIn", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('n_polymorphic_out')
def n_polymorphic_out(T, N, name=None):
  r"""TODO: add doc.

  Args:
    T: A `tf.DType`.
    N: An `int` that is `>= 2`.
    name: A name for the operation (optional).

  Returns:
    A list of `N` `Tensor` objects with type `T`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "NPolymorphicOut", name,
        tld.op_callbacks, "T", T, "N", N)
      return _result
    except _core._FallbackException:
      try:
        return n_polymorphic_out_eager_fallback(
            T=T, N=N, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              n_polymorphic_out, T=T, N=N, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  T = _execute.make_type(T, "T")
  N = _execute.make_int(N, "N")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "NPolymorphicOut", T=T, N=N, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          n_polymorphic_out, T=T, N=N, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op._get_attr_type("T"), "N", _op._get_attr_int("N"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "NPolymorphicOut", _inputs_flat, _attrs, _result)
  return _result

NPolymorphicOut = tf_export("raw_ops.NPolymorphicOut")(_ops.to_raw_op(n_polymorphic_out))


def n_polymorphic_out_eager_fallback(T, N, name, ctx):
  T = _execute.make_type(T, "T")
  N = _execute.make_int(N, "N")
  _inputs_flat = []
  _attrs = ("T", T, "N", N)
  _result = _execute.execute(b"NPolymorphicOut", N, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "NPolymorphicOut", _inputs_flat, _attrs, _result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('n_polymorphic_out_default')
def n_polymorphic_out_default(T=_dtypes.bool, N=2, name=None):
  r"""TODO: add doc.

  Args:
    T: An optional `tf.DType`. Defaults to `tf.bool`.
    N: An optional `int` that is `>= 2`. Defaults to `2`.
    name: A name for the operation (optional).

  Returns:
    A list of `N` `Tensor` objects with type `T`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "NPolymorphicOutDefault", name,
        tld.op_callbacks, "T", T, "N", N)
      return _result
    except _core._FallbackException:
      try:
        return n_polymorphic_out_default_eager_fallback(
            T=T, N=N, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              n_polymorphic_out_default, T=T, N=N, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if T is None:
    T = _dtypes.bool
  T = _execute.make_type(T, "T")
  if N is None:
    N = 2
  N = _execute.make_int(N, "N")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "NPolymorphicOutDefault", T=T, N=N, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          n_polymorphic_out_default, T=T, N=N, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op._get_attr_type("T"), "N", _op._get_attr_int("N"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "NPolymorphicOutDefault", _inputs_flat, _attrs, _result)
  return _result

NPolymorphicOutDefault = tf_export("raw_ops.NPolymorphicOutDefault")(_ops.to_raw_op(n_polymorphic_out_default))


def n_polymorphic_out_default_eager_fallback(T, N, name, ctx):
  if T is None:
    T = _dtypes.bool
  T = _execute.make_type(T, "T")
  if N is None:
    N = 2
  N = _execute.make_int(N, "N")
  _inputs_flat = []
  _attrs = ("T", T, "N", N)
  _result = _execute.execute(b"NPolymorphicOutDefault", N,
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "NPolymorphicOutDefault", _inputs_flat, _attrs, _result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('n_polymorphic_restrict_in')
def n_polymorphic_restrict_in(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of at least 2 `Tensor` objects with the same type in: `string`, `bool`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "NPolymorphicRestrictIn", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return n_polymorphic_restrict_in_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              n_polymorphic_restrict_in, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'n_polymorphic_restrict_in' Op, not %r." % a)
  _attr_N = len(a)
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "NPolymorphicRestrictIn", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          n_polymorphic_restrict_in, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
NPolymorphicRestrictIn = tf_export("raw_ops.NPolymorphicRestrictIn")(_ops.to_raw_op(n_polymorphic_restrict_in))


def n_polymorphic_restrict_in_eager_fallback(a, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'n_polymorphic_restrict_in' Op, not %r." % a)
  _attr_N = len(a)
  _attr_T, a = _execute.args_to_matching_eager(list(a), ctx)
  _inputs_flat = list(a)
  _attrs = ("T", _attr_T, "N", _attr_N)
  _result = _execute.execute(b"NPolymorphicRestrictIn", 0,
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('n_polymorphic_restrict_out')
def n_polymorphic_restrict_out(T, N, name=None):
  r"""TODO: add doc.

  Args:
    T: A `tf.DType` from: `tf.string, tf.bool`.
    N: An `int` that is `>= 2`.
    name: A name for the operation (optional).

  Returns:
    A list of `N` `Tensor` objects with type `T`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "NPolymorphicRestrictOut",
        name, tld.op_callbacks, "T", T, "N", N)
      return _result
    except _core._FallbackException:
      try:
        return n_polymorphic_restrict_out_eager_fallback(
            T=T, N=N, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              n_polymorphic_restrict_out, T=T, N=N, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  T = _execute.make_type(T, "T")
  N = _execute.make_int(N, "N")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "NPolymorphicRestrictOut", T=T, N=N, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          n_polymorphic_restrict_out, T=T, N=N, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op._get_attr_type("T"), "N", _op._get_attr_int("N"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "NPolymorphicRestrictOut", _inputs_flat, _attrs, _result)
  return _result

NPolymorphicRestrictOut = tf_export("raw_ops.NPolymorphicRestrictOut")(_ops.to_raw_op(n_polymorphic_restrict_out))


def n_polymorphic_restrict_out_eager_fallback(T, N, name, ctx):
  T = _execute.make_type(T, "T")
  N = _execute.make_int(N, "N")
  _inputs_flat = []
  _attrs = ("T", T, "N", N)
  _result = _execute.execute(b"NPolymorphicRestrictOut", N,
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "NPolymorphicRestrictOut", _inputs_flat, _attrs, _result)
  return _result

_Namespace_TestStringOutputOutput = collections.namedtuple(
    "Namespace_TestStringOutput",
    ["output1", "output2"])


@_dispatch.add_dispatch_list
@tf_export('namespace_test_string_output')
def namespace_test_string_output(input, name=None):
  r"""TODO: add doc.

  Args:
    input: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (output1, output2).

    output1: A `Tensor` of type `float32`.
    output2: A `Tensor` of type `string`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "Namespace>TestStringOutput",
        name, tld.op_callbacks, input)
      _result = _Namespace_TestStringOutputOutput._make(_result)
      return _result
    except _core._FallbackException:
      try:
        return namespace_test_string_output_eager_fallback(
            input, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              namespace_test_string_output, input=input, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "Namespace>TestStringOutput", input=input, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          namespace_test_string_output, input=input, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "Namespace>TestStringOutput", _inputs_flat, _attrs, _result)
  _result = _Namespace_TestStringOutputOutput._make(_result)
  return _result

Namespace_TestStringOutput = tf_export("raw_ops.Namespace_TestStringOutput")(_ops.to_raw_op(namespace_test_string_output))


def namespace_test_string_output_eager_fallback(input, name, ctx):
  input = _ops.convert_to_tensor(input, _dtypes.float32)
  _inputs_flat = [input]
  _attrs = None
  _result = _execute.execute(b"Namespace>TestStringOutput", 2,
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "Namespace>TestStringOutput", _inputs_flat, _attrs, _result)
  _result = _Namespace_TestStringOutputOutput._make(_result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('none')
def none(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "None", name, tld.op_callbacks)
      return _result
    except _core._FallbackException:
      try:
        return none_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              none, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "None", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          none, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
None_ = tf_export("raw_ops.None_")(_ops.to_raw_op(none))


def none_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"None", 0, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('old')
def old(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "Old", name, tld.op_callbacks)
      return _result
    except _core._FallbackException:
      try:
        return old_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              old, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "Old", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          old, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
Old = tf_export("raw_ops.Old")(_ops.to_raw_op(old))


def old_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"Old", 0, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('op_with_default_attr')
def op_with_default_attr(default_float=123, name=None):
  r"""TODO: add doc.

  Args:
    default_float: An optional `float`. Defaults to `123`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "OpWithDefaultAttr", name,
        tld.op_callbacks, "default_float", default_float)
      return _result
    except _core._FallbackException:
      try:
        return op_with_default_attr_eager_fallback(
            default_float=default_float, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              op_with_default_attr, default_float=default_float, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if default_float is None:
    default_float = 123
  default_float = _execute.make_float(default_float, "default_float")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "OpWithDefaultAttr", default_float=default_float, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          op_with_default_attr, default_float=default_float, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("default_float", _op.get_attr("default_float"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "OpWithDefaultAttr", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

OpWithDefaultAttr = tf_export("raw_ops.OpWithDefaultAttr")(_ops.to_raw_op(op_with_default_attr))


def op_with_default_attr_eager_fallback(default_float, name, ctx):
  if default_float is None:
    default_float = 123
  default_float = _execute.make_float(default_float, "default_float")
  _inputs_flat = []
  _attrs = ("default_float", default_float)
  _result = _execute.execute(b"OpWithDefaultAttr", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "OpWithDefaultAttr", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('op_with_future_default_attr')
def op_with_future_default_attr(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "OpWithFutureDefaultAttr",
        name, tld.op_callbacks)
      return _result
    except _core._FallbackException:
      try:
        return op_with_future_default_attr_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              op_with_future_default_attr, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "OpWithFutureDefaultAttr", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          op_with_future_default_attr, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
OpWithFutureDefaultAttr = tf_export("raw_ops.OpWithFutureDefaultAttr")(_ops.to_raw_op(op_with_future_default_attr))


def op_with_future_default_attr_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"OpWithFutureDefaultAttr", 0,
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('out_t')
def out_t(T, name=None):
  r"""TODO: add doc.

  Args:
    T: A `tf.DType`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `T`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "OutT", name, tld.op_callbacks,
        "T", T)
      return _result
    except _core._FallbackException:
      try:
        return out_t_eager_fallback(
            T=T, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              out_t, T=T, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  T = _execute.make_type(T, "T")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "OutT", T=T, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          out_t, T=T, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op._get_attr_type("T"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "OutT", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

OutT = tf_export("raw_ops.OutT")(_ops.to_raw_op(out_t))


def out_t_eager_fallback(T, name, ctx):
  T = _execute.make_type(T, "T")
  _inputs_flat = []
  _attrs = ("T", T)
  _result = _execute.execute(b"OutT", 1, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "OutT", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('out_type_list')
def out_type_list(T, name=None):
  r"""TODO: add doc.

  Args:
    T: A list of `tf.DTypes`.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `T`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "OutTypeList", name,
        tld.op_callbacks, "T", T)
      return _result
    except _core._FallbackException:
      try:
        return out_type_list_eager_fallback(
            T=T, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              out_type_list, T=T, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(T, (list, tuple)):
    raise TypeError(
        "Expected list for 'T' argument to "
        "'out_type_list' Op, not %r." % T)
  T = [_execute.make_type(_t, "T") for _t in T]
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "OutTypeList", T=T, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          out_type_list, T=T, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op.get_attr("T"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "OutTypeList", _inputs_flat, _attrs, _result)
  return _result

OutTypeList = tf_export("raw_ops.OutTypeList")(_ops.to_raw_op(out_type_list))


def out_type_list_eager_fallback(T, name, ctx):
  if not isinstance(T, (list, tuple)):
    raise TypeError(
        "Expected list for 'T' argument to "
        "'out_type_list' Op, not %r." % T)
  T = [_execute.make_type(_t, "T") for _t in T]
  _inputs_flat = []
  _attrs = ("T", T)
  _result = _execute.execute(b"OutTypeList", len(T), inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "OutTypeList", _inputs_flat, _attrs, _result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('out_type_list_restrict')
def out_type_list_restrict(t, name=None):
  r"""TODO: add doc.

  Args:
    t: A list of `tf.DTypes` from: `tf.string, tf.bool` that has length `>= 1`.
    name: A name for the operation (optional).

  Returns:
    A list of `Tensor` objects of type `t`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "OutTypeListRestrict", name,
        tld.op_callbacks, "t", t)
      return _result
    except _core._FallbackException:
      try:
        return out_type_list_restrict_eager_fallback(
            t=t, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              out_type_list_restrict, t=t, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(t, (list, tuple)):
    raise TypeError(
        "Expected list for 't' argument to "
        "'out_type_list_restrict' Op, not %r." % t)
  t = [_execute.make_type(_t, "t") for _t in t]
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "OutTypeListRestrict", t=t, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          out_type_list_restrict, t=t, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("t", _op.get_attr("t"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "OutTypeListRestrict", _inputs_flat, _attrs, _result)
  return _result

OutTypeListRestrict = tf_export("raw_ops.OutTypeListRestrict")(_ops.to_raw_op(out_type_list_restrict))


def out_type_list_restrict_eager_fallback(t, name, ctx):
  if not isinstance(t, (list, tuple)):
    raise TypeError(
        "Expected list for 't' argument to "
        "'out_type_list_restrict' Op, not %r." % t)
  t = [_execute.make_type(_t, "t") for _t in t]
  _inputs_flat = []
  _attrs = ("t", t)
  _result = _execute.execute(b"OutTypeListRestrict", len(t),
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "OutTypeListRestrict", _inputs_flat, _attrs, _result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('polymorphic')
def polymorphic(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `a`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "Polymorphic", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return polymorphic_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              polymorphic, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "Polymorphic", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          polymorphic, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op._get_attr_type("T"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "Polymorphic", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

Polymorphic = tf_export("raw_ops.Polymorphic")(_ops.to_raw_op(polymorphic))


def polymorphic_eager_fallback(a, name, ctx):
  _attr_T, (a,) = _execute.args_to_matching_eager([a], ctx)
  _inputs_flat = [a]
  _attrs = ("T", _attr_T)
  _result = _execute.execute(b"Polymorphic", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "Polymorphic", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('polymorphic_default_out')
def polymorphic_default_out(T=_dtypes.string, name=None):
  r"""TODO: add doc.

  Args:
    T: An optional `tf.DType`. Defaults to `tf.string`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `T`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "PolymorphicDefaultOut", name,
        tld.op_callbacks, "T", T)
      return _result
    except _core._FallbackException:
      try:
        return polymorphic_default_out_eager_fallback(
            T=T, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              polymorphic_default_out, T=T, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if T is None:
    T = _dtypes.string
  T = _execute.make_type(T, "T")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "PolymorphicDefaultOut", T=T, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          polymorphic_default_out, T=T, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op._get_attr_type("T"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "PolymorphicDefaultOut", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

PolymorphicDefaultOut = tf_export("raw_ops.PolymorphicDefaultOut")(_ops.to_raw_op(polymorphic_default_out))


def polymorphic_default_out_eager_fallback(T, name, ctx):
  if T is None:
    T = _dtypes.string
  T = _execute.make_type(T, "T")
  _inputs_flat = []
  _attrs = ("T", T)
  _result = _execute.execute(b"PolymorphicDefaultOut", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "PolymorphicDefaultOut", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('polymorphic_out')
def polymorphic_out(T, name=None):
  r"""TODO: add doc.

  Args:
    T: A `tf.DType`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `T`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "PolymorphicOut", name,
        tld.op_callbacks, "T", T)
      return _result
    except _core._FallbackException:
      try:
        return polymorphic_out_eager_fallback(
            T=T, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              polymorphic_out, T=T, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  T = _execute.make_type(T, "T")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "PolymorphicOut", T=T, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          polymorphic_out, T=T, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op._get_attr_type("T"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "PolymorphicOut", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

PolymorphicOut = tf_export("raw_ops.PolymorphicOut")(_ops.to_raw_op(polymorphic_out))


def polymorphic_out_eager_fallback(T, name, ctx):
  T = _execute.make_type(T, "T")
  _inputs_flat = []
  _attrs = ("T", T)
  _result = _execute.execute(b"PolymorphicOut", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "PolymorphicOut", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('ref_in')
def ref_in(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A mutable `Tensor`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    raise RuntimeError("ref_in op does not support eager execution. Arg 'a' is a ref.")
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "RefIn", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          ref_in, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
RefIn = tf_export("raw_ops.RefIn")(_ops.to_raw_op(ref_in))


def ref_in_eager_fallback(a, name, ctx):
  raise RuntimeError("ref_in op does not support eager execution. Arg 'a' is a ref.")

@_dispatch.add_dispatch_list
@tf_export('ref_input_float_input')
def ref_input_float_input(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type mutable `float32`.
    b: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    raise RuntimeError("ref_input_float_input op does not support eager execution. Arg 'a' is a ref.")
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "RefInputFloatInput", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          ref_input_float_input, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
RefInputFloatInput = tf_export("raw_ops.RefInputFloatInput")(_ops.to_raw_op(ref_input_float_input))


def ref_input_float_input_eager_fallback(a, b, name, ctx):
  raise RuntimeError("ref_input_float_input op does not support eager execution. Arg 'a' is a ref.")

@_dispatch.add_dispatch_list
@tf_export('ref_input_float_input_int_output')
def ref_input_float_input_int_output(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type mutable `float32`.
    b: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    raise RuntimeError("ref_input_float_input_int_output op does not support eager execution. Arg 'a' is a ref.")
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "RefInputFloatInputIntOutput", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          ref_input_float_input_int_output, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "RefInputFloatInputIntOutput", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

RefInputFloatInputIntOutput = tf_export("raw_ops.RefInputFloatInputIntOutput")(_ops.to_raw_op(ref_input_float_input_int_output))


def ref_input_float_input_int_output_eager_fallback(a, b, name, ctx):
  raise RuntimeError("ref_input_float_input_int_output op does not support eager execution. Arg 'a' is a ref.")

@_dispatch.add_dispatch_list
@tf_export('ref_input_int_input')
def ref_input_int_input(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type mutable `int32`.
    b: A `Tensor` of type `int32`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    raise RuntimeError("ref_input_int_input op does not support eager execution. Arg 'a' is a ref.")
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "RefInputIntInput", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          ref_input_int_input, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
RefInputIntInput = tf_export("raw_ops.RefInputIntInput")(_ops.to_raw_op(ref_input_int_input))


def ref_input_int_input_eager_fallback(a, b, name, ctx):
  raise RuntimeError("ref_input_int_input op does not support eager execution. Arg 'a' is a ref.")

@_dispatch.add_dispatch_list
@tf_export('ref_out')
def ref_out(T, name=None):
  r"""TODO: add doc.

  Args:
    T: A `tf.DType`.
    name: A name for the operation (optional).

  Returns:
    A mutable `Tensor` of type `T`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    raise RuntimeError("ref_out op does not support eager execution. Arg 'a' is a ref.")
  # Add nodes to the TensorFlow graph.
  T = _execute.make_type(T, "T")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "RefOut", T=T, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          ref_out, T=T, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op._get_attr_type("T"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "RefOut", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

RefOut = tf_export("raw_ops.RefOut")(_ops.to_raw_op(ref_out))


def ref_out_eager_fallback(T, name, ctx):
  raise RuntimeError("ref_out op does not support eager execution. Arg 'a' is a ref.")

@_dispatch.add_dispatch_list
@tf_export('ref_output')
def ref_output(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type mutable `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    raise RuntimeError("ref_output op does not support eager execution. Arg 'a' is a ref.")
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "RefOutput", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          ref_output, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "RefOutput", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

RefOutput = tf_export("raw_ops.RefOutput")(_ops.to_raw_op(ref_output))


def ref_output_eager_fallback(name, ctx):
  raise RuntimeError("ref_output op does not support eager execution. Arg 'a' is a ref.")
_RefOutputFloatOutputOutput = collections.namedtuple(
    "RefOutputFloatOutput",
    ["a", "b"])


@_dispatch.add_dispatch_list
@tf_export('ref_output_float_output')
def ref_output_float_output(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (a, b).

    a: A `Tensor` of type mutable `float32`.
    b: A `Tensor` of type `float32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    raise RuntimeError("ref_output_float_output op does not support eager execution. Arg 'a' is a ref.")
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "RefOutputFloatOutput", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          ref_output_float_output, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "RefOutputFloatOutput", _inputs_flat, _attrs, _result)
  _result = _RefOutputFloatOutputOutput._make(_result)
  return _result

RefOutputFloatOutput = tf_export("raw_ops.RefOutputFloatOutput")(_ops.to_raw_op(ref_output_float_output))


def ref_output_float_output_eager_fallback(name, ctx):
  raise RuntimeError("ref_output_float_output op does not support eager execution. Arg 'a' is a ref.")

@_dispatch.add_dispatch_list
@tf_export('requires_older_graph_version')
def requires_older_graph_version(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "RequiresOlderGraphVersion",
        name, tld.op_callbacks)
      return _result
    except _core._FallbackException:
      try:
        return requires_older_graph_version_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              requires_older_graph_version, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "RequiresOlderGraphVersion", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          requires_older_graph_version, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "RequiresOlderGraphVersion", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

RequiresOlderGraphVersion = tf_export("raw_ops.RequiresOlderGraphVersion")(_ops.to_raw_op(requires_older_graph_version))


def requires_older_graph_version_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"RequiresOlderGraphVersion", 1,
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "RequiresOlderGraphVersion", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('reserved_attr')
def reserved_attr(range, name=None):
  r"""TODO: add doc.

  Args:
    range: An `int`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "ReservedAttr", name,
        tld.op_callbacks, "range", range)
      return _result
    except _core._FallbackException:
      try:
        return reserved_attr_eager_fallback(
            range=range, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              reserved_attr, range=range, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  range = _execute.make_int(range, "range")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "ReservedAttr", range=range, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          reserved_attr, range=range, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
ReservedAttr = tf_export("raw_ops.ReservedAttr")(_ops.to_raw_op(reserved_attr))


def reserved_attr_eager_fallback(range, name, ctx):
  range = _execute.make_int(range, "range")
  _inputs_flat = []
  _attrs = ("range", range)
  _result = _execute.execute(b"ReservedAttr", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('reserved_input')
def reserved_input(input, name=None):
  r"""TODO: add doc.

  Args:
    input: A `Tensor` of type `int32`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "ReservedInput", name,
        tld.op_callbacks, input)
      return _result
    except _core._FallbackException:
      try:
        return reserved_input_eager_fallback(
            input, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              reserved_input, input=input, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "ReservedInput", input=input, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          reserved_input, input=input, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
ReservedInput = tf_export("raw_ops.ReservedInput")(_ops.to_raw_op(reserved_input))


def reserved_input_eager_fallback(input, name, ctx):
  input = _ops.convert_to_tensor(input, _dtypes.int32)
  _inputs_flat = [input]
  _attrs = None
  _result = _execute.execute(b"ReservedInput", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('resource_create_op')
def resource_create_op(resource, name=None):
  r"""TODO: add doc.

  Args:
    resource: A `Tensor` of type `resource`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "ResourceCreateOp", name,
        tld.op_callbacks, resource)
      return _result
    except _core._FallbackException:
      try:
        return resource_create_op_eager_fallback(
            resource, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              resource_create_op, resource=resource, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "ResourceCreateOp", resource=resource, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          resource_create_op, resource=resource, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
ResourceCreateOp = tf_export("raw_ops.ResourceCreateOp")(_ops.to_raw_op(resource_create_op))


def resource_create_op_eager_fallback(resource, name, ctx):
  resource = _ops.convert_to_tensor(resource, _dtypes.resource)
  _inputs_flat = [resource]
  _attrs = None
  _result = _execute.execute(b"ResourceCreateOp", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('resource_initialized_op')
def resource_initialized_op(resource, name=None):
  r"""TODO: add doc.

  Args:
    resource: A `Tensor` of type `resource`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `bool`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "ResourceInitializedOp", name,
        tld.op_callbacks, resource)
      return _result
    except _core._FallbackException:
      try:
        return resource_initialized_op_eager_fallback(
            resource, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              resource_initialized_op, resource=resource, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "ResourceInitializedOp", resource=resource, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          resource_initialized_op, resource=resource, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "ResourceInitializedOp", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

ResourceInitializedOp = tf_export("raw_ops.ResourceInitializedOp")(_ops.to_raw_op(resource_initialized_op))


def resource_initialized_op_eager_fallback(resource, name, ctx):
  resource = _ops.convert_to_tensor(resource, _dtypes.resource)
  _inputs_flat = [resource]
  _attrs = None
  _result = _execute.execute(b"ResourceInitializedOp", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "ResourceInitializedOp", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('resource_using_op')
def resource_using_op(resource, name=None):
  r"""TODO: add doc.

  Args:
    resource: A `Tensor` of type `resource`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "ResourceUsingOp", name,
        tld.op_callbacks, resource)
      return _result
    except _core._FallbackException:
      try:
        return resource_using_op_eager_fallback(
            resource, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              resource_using_op, resource=resource, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "ResourceUsingOp", resource=resource, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          resource_using_op, resource=resource, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
ResourceUsingOp = tf_export("raw_ops.ResourceUsingOp")(_ops.to_raw_op(resource_using_op))


def resource_using_op_eager_fallback(resource, name, ctx):
  resource = _ops.convert_to_tensor(resource, _dtypes.resource)
  _inputs_flat = [resource]
  _attrs = None
  _result = _execute.execute(b"ResourceUsingOp", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('restrict')
def restrict(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor`. Must be one of the following types: `string`, `bool`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `a`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "Restrict", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return restrict_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              restrict, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "Restrict", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          restrict, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op._get_attr_type("T"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "Restrict", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

Restrict = tf_export("raw_ops.Restrict")(_ops.to_raw_op(restrict))


def restrict_eager_fallback(a, name, ctx):
  _attr_T, (a,) = _execute.args_to_matching_eager([a], ctx)
  _inputs_flat = [a]
  _attrs = ("T", _attr_T)
  _result = _execute.execute(b"Restrict", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "Restrict", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('simple')
def simple(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type `int32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "Simple", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return simple_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              simple, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "Simple", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          simple, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "Simple", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

Simple = tf_export("raw_ops.Simple")(_ops.to_raw_op(simple))


def simple_eager_fallback(a, name, ctx):
  a = _ops.convert_to_tensor(a, _dtypes.int32)
  _inputs_flat = [a]
  _attrs = None
  _result = _execute.execute(b"Simple", 1, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "Simple", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('simple_struct')
def simple_struct(n_a, name=None):
  r"""TODO: add doc.

  Args:
    n_a: An `int` that is `>= 0`.
    name: A name for the operation (optional).

  Returns:
    A list of `n_a` `Tensor` objects with type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "SimpleStruct", name,
        tld.op_callbacks, "n_a", n_a)
      return _result
    except _core._FallbackException:
      try:
        return simple_struct_eager_fallback(
            n_a=n_a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              simple_struct, n_a=n_a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  n_a = _execute.make_int(n_a, "n_a")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "SimpleStruct", n_a=n_a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          simple_struct, n_a=n_a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("n_a", _op._get_attr_int("n_a"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "SimpleStruct", _inputs_flat, _attrs, _result)
  return _result

SimpleStruct = tf_export("raw_ops.SimpleStruct")(_ops.to_raw_op(simple_struct))


def simple_struct_eager_fallback(n_a, name, ctx):
  n_a = _execute.make_int(n_a, "n_a")
  _inputs_flat = []
  _attrs = ("n_a", n_a)
  _result = _execute.execute(b"SimpleStruct", n_a, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "SimpleStruct", _inputs_flat, _attrs, _result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('string_list_attr')
def string_list_attr(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of `strings`.
    b: A `string`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "StringListAttr", name,
        tld.op_callbacks, "a", a, "b", b)
      return _result
    except _core._FallbackException:
      try:
        return string_list_attr_eager_fallback(
            a=a, b=b, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              string_list_attr, a=a, b=b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'string_list_attr' Op, not %r." % a)
  a = [_execute.make_str(_s, "a") for _s in a]
  b = _execute.make_str(b, "b")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "StringListAttr", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          string_list_attr, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
StringListAttr = tf_export("raw_ops.StringListAttr")(_ops.to_raw_op(string_list_attr))


def string_list_attr_eager_fallback(a, b, name, ctx):
  if not isinstance(a, (list, tuple)):
    raise TypeError(
        "Expected list for 'a' argument to "
        "'string_list_attr' Op, not %r." % a)
  a = [_execute.make_str(_s, "a") for _s in a]
  b = _execute.make_str(b, "b")
  _inputs_flat = []
  _attrs = ("a", a, "b", b)
  _result = _execute.execute(b"StringListAttr", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('stub_resource_handle_op')
def stub_resource_handle_op(container="", shared_name="", name=None):
  r"""TODO: add doc.

  Args:
    container: An optional `string`. Defaults to `""`.
    shared_name: An optional `string`. Defaults to `""`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `resource`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "StubResourceHandleOp", name,
        tld.op_callbacks, "container", container, "shared_name", shared_name)
      return _result
    except _core._FallbackException:
      try:
        return stub_resource_handle_op_eager_fallback(
            container=container, shared_name=shared_name, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              stub_resource_handle_op, container=container,
                                       shared_name=shared_name, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if container is None:
    container = ""
  container = _execute.make_str(container, "container")
  if shared_name is None:
    shared_name = ""
  shared_name = _execute.make_str(shared_name, "shared_name")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "StubResourceHandleOp", container=container, shared_name=shared_name,
                                name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          stub_resource_handle_op, container=container,
                                   shared_name=shared_name, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("container", _op.get_attr("container"), "shared_name",
              _op.get_attr("shared_name"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "StubResourceHandleOp", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

StubResourceHandleOp = tf_export("raw_ops.StubResourceHandleOp")(_ops.to_raw_op(stub_resource_handle_op))


def stub_resource_handle_op_eager_fallback(container, shared_name, name, ctx):
  if container is None:
    container = ""
  container = _execute.make_str(container, "container")
  if shared_name is None:
    shared_name = ""
  shared_name = _execute.make_str(shared_name, "shared_name")
  _inputs_flat = []
  _attrs = ("container", container, "shared_name", shared_name)
  _result = _execute.execute(b"StubResourceHandleOp", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "StubResourceHandleOp", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('test_attr')
def test_attr(T, name=None):
  r"""TODO: add doc.

  Args:
    T: A `tf.DType` from: `tf.float32, tf.float64`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `T`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "TestAttr", name,
        tld.op_callbacks, "T", T)
      return _result
    except _core._FallbackException:
      try:
        return test_attr_eager_fallback(
            T=T, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              test_attr, T=T, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  T = _execute.make_type(T, "T")
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "TestAttr", T=T, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          test_attr, T=T, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op._get_attr_type("T"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "TestAttr", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

TestAttr = tf_export("raw_ops.TestAttr")(_ops.to_raw_op(test_attr))


def test_attr_eager_fallback(T, name, ctx):
  T = _execute.make_type(T, "T")
  _inputs_flat = []
  _attrs = ("T", T)
  _result = _execute.execute(b"TestAttr", 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "TestAttr", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

_TestStringOutputOutput = collections.namedtuple(
    "TestStringOutput",
    ["output1", "output2"])


@_dispatch.add_dispatch_list
@tf_export('test_string_output')
def test_string_output(input, name=None):
  r"""TODO: add doc.

  Args:
    input: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (output1, output2).

    output1: A `Tensor` of type `float32`.
    output2: A `Tensor` of type `string`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "TestStringOutput", name,
        tld.op_callbacks, input)
      _result = _TestStringOutputOutput._make(_result)
      return _result
    except _core._FallbackException:
      try:
        return test_string_output_eager_fallback(
            input, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              test_string_output, input=input, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "TestStringOutput", input=input, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          test_string_output, input=input, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "TestStringOutput", _inputs_flat, _attrs, _result)
  _result = _TestStringOutputOutput._make(_result)
  return _result

TestStringOutput = tf_export("raw_ops.TestStringOutput")(_ops.to_raw_op(test_string_output))


def test_string_output_eager_fallback(input, name, ctx):
  input = _ops.convert_to_tensor(input, _dtypes.float32)
  _inputs_flat = [input]
  _attrs = None
  _result = _execute.execute(b"TestStringOutput", 2, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "TestStringOutput", _inputs_flat, _attrs, _result)
  _result = _TestStringOutputOutput._make(_result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('two_float_inputs')
def two_float_inputs(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type `float32`.
    b: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "TwoFloatInputs", name,
        tld.op_callbacks, a, b)
      return _result
    except _core._FallbackException:
      try:
        return two_float_inputs_eager_fallback(
            a, b, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              two_float_inputs, a=a, b=b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "TwoFloatInputs", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          two_float_inputs, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
TwoFloatInputs = tf_export("raw_ops.TwoFloatInputs")(_ops.to_raw_op(two_float_inputs))


def two_float_inputs_eager_fallback(a, b, name, ctx):
  a = _ops.convert_to_tensor(a, _dtypes.float32)
  b = _ops.convert_to_tensor(b, _dtypes.float32)
  _inputs_flat = [a, b]
  _attrs = None
  _result = _execute.execute(b"TwoFloatInputs", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('two_float_inputs_float_output')
def two_float_inputs_float_output(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type `float32`.
    b: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `float32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "TwoFloatInputsFloatOutput",
        name, tld.op_callbacks, a, b)
      return _result
    except _core._FallbackException:
      try:
        return two_float_inputs_float_output_eager_fallback(
            a, b, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              two_float_inputs_float_output, a=a, b=b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "TwoFloatInputsFloatOutput", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          two_float_inputs_float_output, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "TwoFloatInputsFloatOutput", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

TwoFloatInputsFloatOutput = tf_export("raw_ops.TwoFloatInputsFloatOutput")(_ops.to_raw_op(two_float_inputs_float_output))


def two_float_inputs_float_output_eager_fallback(a, b, name, ctx):
  a = _ops.convert_to_tensor(a, _dtypes.float32)
  b = _ops.convert_to_tensor(b, _dtypes.float32)
  _inputs_flat = [a, b]
  _attrs = None
  _result = _execute.execute(b"TwoFloatInputsFloatOutput", 1,
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "TwoFloatInputsFloatOutput", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


@_dispatch.add_dispatch_list
@tf_export('two_float_inputs_int_output')
def two_float_inputs_int_output(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type `float32`.
    b: A `Tensor` of type `float32`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor` of type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "TwoFloatInputsIntOutput",
        name, tld.op_callbacks, a, b)
      return _result
    except _core._FallbackException:
      try:
        return two_float_inputs_int_output_eager_fallback(
            a, b, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              two_float_inputs_int_output, a=a, b=b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "TwoFloatInputsIntOutput", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          two_float_inputs_int_output, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "TwoFloatInputsIntOutput", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

TwoFloatInputsIntOutput = tf_export("raw_ops.TwoFloatInputsIntOutput")(_ops.to_raw_op(two_float_inputs_int_output))


def two_float_inputs_int_output_eager_fallback(a, b, name, ctx):
  a = _ops.convert_to_tensor(a, _dtypes.float32)
  b = _ops.convert_to_tensor(b, _dtypes.float32)
  _inputs_flat = [a, b]
  _attrs = None
  _result = _execute.execute(b"TwoFloatInputsIntOutput", 1,
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "TwoFloatInputsIntOutput", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

_TwoFloatOutputsOutput = collections.namedtuple(
    "TwoFloatOutputs",
    ["a", "b"])


@_dispatch.add_dispatch_list
@tf_export('two_float_outputs')
def two_float_outputs(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (a, b).

    a: A `Tensor` of type `float32`.
    b: A `Tensor` of type `float32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "TwoFloatOutputs", name,
        tld.op_callbacks)
      _result = _TwoFloatOutputsOutput._make(_result)
      return _result
    except _core._FallbackException:
      try:
        return two_float_outputs_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              two_float_outputs, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "TwoFloatOutputs", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          two_float_outputs, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "TwoFloatOutputs", _inputs_flat, _attrs, _result)
  _result = _TwoFloatOutputsOutput._make(_result)
  return _result

TwoFloatOutputs = tf_export("raw_ops.TwoFloatOutputs")(_ops.to_raw_op(two_float_outputs))


def two_float_outputs_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"TwoFloatOutputs", 2, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "TwoFloatOutputs", _inputs_flat, _attrs, _result)
  _result = _TwoFloatOutputsOutput._make(_result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('two_int_inputs')
def two_int_inputs(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor` of type `int32`.
    b: A `Tensor` of type `int32`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "TwoIntInputs", name,
        tld.op_callbacks, a, b)
      return _result
    except _core._FallbackException:
      try:
        return two_int_inputs_eager_fallback(
            a, b, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              two_int_inputs, a=a, b=b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "TwoIntInputs", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          two_int_inputs, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
TwoIntInputs = tf_export("raw_ops.TwoIntInputs")(_ops.to_raw_op(two_int_inputs))


def two_int_inputs_eager_fallback(a, b, name, ctx):
  a = _ops.convert_to_tensor(a, _dtypes.int32)
  b = _ops.convert_to_tensor(b, _dtypes.int32)
  _inputs_flat = [a, b]
  _attrs = None
  _result = _execute.execute(b"TwoIntInputs", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result

_TwoIntOutputsOutput = collections.namedtuple(
    "TwoIntOutputs",
    ["a", "b"])


@_dispatch.add_dispatch_list
@tf_export('two_int_outputs')
def two_int_outputs(name=None):
  r"""TODO: add doc.

  Args:
    name: A name for the operation (optional).

  Returns:
    A tuple of `Tensor` objects (a, b).

    a: A `Tensor` of type `int32`.
    b: A `Tensor` of type `int32`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "TwoIntOutputs", name,
        tld.op_callbacks)
      _result = _TwoIntOutputsOutput._make(_result)
      return _result
    except _core._FallbackException:
      try:
        return two_int_outputs_eager_fallback(
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              two_int_outputs, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "TwoIntOutputs", name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          two_int_outputs, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ()
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "TwoIntOutputs", _inputs_flat, _attrs, _result)
  _result = _TwoIntOutputsOutput._make(_result)
  return _result

TwoIntOutputs = tf_export("raw_ops.TwoIntOutputs")(_ops.to_raw_op(two_int_outputs))


def two_int_outputs_eager_fallback(name, ctx):
  _inputs_flat = []
  _attrs = None
  _result = _execute.execute(b"TwoIntOutputs", 2, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "TwoIntOutputs", _inputs_flat, _attrs, _result)
  _result = _TwoIntOutputsOutput._make(_result)
  return _result


@_dispatch.add_dispatch_list
@tf_export('two_refs_in')
def two_refs_in(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A mutable `Tensor`.
    b: A mutable `Tensor`. Must have the same type as `a`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    raise RuntimeError("two_refs_in op does not support eager execution. Arg 'b' is a ref.")
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "TwoRefsIn", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          two_refs_in, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
TwoRefsIn = tf_export("raw_ops.TwoRefsIn")(_ops.to_raw_op(two_refs_in))


def two_refs_in_eager_fallback(a, b, name, ctx):
  raise RuntimeError("two_refs_in op does not support eager execution. Arg 'b' is a ref.")

@_dispatch.add_dispatch_list
@tf_export('type_list')
def type_list(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of `Tensor` objects.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "TypeList", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return type_list_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              type_list, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "TypeList", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          type_list, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
TypeList = tf_export("raw_ops.TypeList")(_ops.to_raw_op(type_list))


def type_list_eager_fallback(a, name, ctx):
  _attr_T, a = _execute.convert_to_mixed_eager_tensors(a, ctx)
  _inputs_flat = list(a)
  _attrs = ("T", _attr_T)
  _result = _execute.execute(b"TypeList", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('type_list_restrict')
def type_list_restrict(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of `Tensor` objects with types from: `string`, `bool`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "TypeListRestrict", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return type_list_restrict_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              type_list_restrict, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "TypeListRestrict", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          type_list_restrict, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
TypeListRestrict = tf_export("raw_ops.TypeListRestrict")(_ops.to_raw_op(type_list_restrict))


def type_list_restrict_eager_fallback(a, name, ctx):
  _attr_T, a = _execute.convert_to_mixed_eager_tensors(a, ctx)
  _inputs_flat = list(a)
  _attrs = ("T", _attr_T)
  _result = _execute.execute(b"TypeListRestrict", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('type_list_twice')
def type_list_twice(a, b, name=None):
  r"""TODO: add doc.

  Args:
    a: A list of `Tensor` objects.
    b: A list of `Tensor` objects. Must have the same type as `a`.
    name: A name for the operation (optional).

  Returns:
    The created Operation.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "TypeListTwice", name,
        tld.op_callbacks, a, b)
      return _result
    except _core._FallbackException:
      try:
        return type_list_twice_eager_fallback(
            a, b, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              type_list_twice, a=a, b=b, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "TypeListTwice", a=a, b=b, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          type_list_twice, a=a, b=b, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  return _op
TypeListTwice = tf_export("raw_ops.TypeListTwice")(_ops.to_raw_op(type_list_twice))


def type_list_twice_eager_fallback(a, b, name, ctx):
  _attr_T, (a, b) = _execute.args_to_mixed_eager_tensors((a, b), ctx)
  _inputs_flat = list(a) + list(b)
  _attrs = ("T", _attr_T)
  _result = _execute.execute(b"TypeListTwice", 0, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  _result = None
  return _result


@_dispatch.add_dispatch_list
@tf_export('unary')
def unary(a, name=None):
  r"""TODO: add doc.

  Args:
    a: A `Tensor`.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `a`.
  """
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, "Unary", name,
        tld.op_callbacks, a)
      return _result
    except _core._FallbackException:
      try:
        return unary_eager_fallback(
            a, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
      except (TypeError, ValueError):
        result = _dispatch.dispatch(
              unary, a=a, name=name)
        if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
          return result
        raise
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  try:
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
        "Unary", a=a, name=name)
  except (TypeError, ValueError):
    result = _dispatch.dispatch(
          unary, a=a, name=name)
    if result is not _dispatch.OpDispatcher.NOT_SUPPORTED:
      return result
    raise
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = ("T", _op._get_attr_type("T"))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        "Unary", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

Unary = tf_export("raw_ops.Unary")(_ops.to_raw_op(unary))


def unary_eager_fallback(a, name, ctx):
  _attr_T, (a,) = _execute.args_to_matching_eager([a], ctx)
  _inputs_flat = [a]
  _attrs = ("T", _attr_T)
  _result = _execute.execute(b"Unary", 1, inputs=_inputs_flat, attrs=_attrs,
                             ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        "Unary", _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

